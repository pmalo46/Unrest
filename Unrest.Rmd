---
title: "Unrest"
author: "Patrick Maloney"
date: "3/20/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Intro

 This Project will look at events of civil unrest, and use historical data to forecast the potential duration of such events.

### Importing data

This data comes from the SPEED data set, which was run out of the University of Illinois and compiles unrest events from 1946 to 2005. I have taken a subset of the data that includes events outside the US that lasted longer than one day.

```{r}
library(RCurl)
library(tidyverse)
library(VIM)
library(dplyr)

data_raw <- read.csv("https://raw.githubusercontent.com/pmalo46/Unrest/main/civil-unrest-event-data-QueryResult.csv")

tail(data_raw, 25)

```


### EDA

This data encompasses a number of decades and covers events across the world, so there is likely to be lots of missing data. View the codebook file in this project  repository for the SPEED project's definition of each variable in the dataset.

```{r}
str(data_raw)
summary(data_raw)
```

```{r}
aggr(data_raw)
```

I need to drop the columns that are majority missing values. 

```{r}
cond1 <- sapply(data_raw, function(col) sum(is.na(col)) > 2000)
cond2 <- sapply(data_raw, function(col) sum(col == "") > 2000)
mask <- !(cond1 | cond2)
df <- data_raw[, !cond1, drop=FALSE]
summary(df)
str(df)
```

```{r}
df <- df[-c(5:13, 25:29)] 
str(df)
```

I have now removed columns with a majority of missing values and dropped columns with specific names like organizations perpatraiting events or victim groups. I have also removed columns containing metadata from the publications.

```{r}
aggr(df)
summary(df)
```

```{r}
boxplot(df$day_span)
summary(df$day_span)
qqnorm(df$day_span, pch = 1, frame = FALSE)
qqline(df$day_span, col = "steelblue", lwd = 2)
hist(df1$day_span, breaks = 800, xlim = c(2, 600))
```

I was planning to use day_span as my response variable for a multivariate linear regression model, but after checking the conditions for regression, I can see that this variable is not normally distributed. A classification model might be a better choice. Now The data types must be fixed. Many categorical variables are listed as integers, where they should be factors, since the numbers correspond to categorical values, not actual integers.

```{r}
df <-  subset(df, select = -c(eventid, aid, year, code_year, code_month, code_day, code_date, gp3, gp4, gp7, gp8, ambig_wgt, from_eid, to_eid, pinpoint, date_typ, ctry_bias, quasi_event, n_killed_p))

df$month <- factor(df$month)
df$know_ini <- factor(df$know_ini)
df$ev_type <- factor(df$ev_type)
df$loc_type <- factor(df$loc_type)
df$weap_grd <- factor(df$weap_grd)
df$e_length <- factor(df$e_length)
df$region <- factor(df$region)
df$weapon <- factor(df$weapon)

str(df)
```

Now that we have dropped unhelpful columns, let's slice the data to only explore destabalizing events and ignore quasi-events.

```{r}
df1 <- filter(df, event==TRUE)
head(df1, 25)

```

The e_length variable seems to have some discrepancy with the day_span value. In many cases the values don't match up. Therefore, I'm going to create a new variable for event duration that will put the data into buckets based on day_span

```{r}
df1 <- df1 %>% mutate(duration = case_when(day_span <= 7 ~ "1",
                            day_span > 7 & day_span <= 30 ~ "2", 
                           day_span > 30 ~ "3"))
df1$duration <- factor(df1$duration)
head(df1, 25)

```

It seems that the month and day values are taken as an average instead of the start date. lets add other columns for the start month and start day using the julian date
```{r}
jul_conv <- function (sdate, weekday = FALSE) 
{
    attr(sdate, "class") <- NULL
    sdate <- floor(sdate + 2431456)
    wday <- as.integer((sdate + 1)%%7 + 1)
    temp <- ((sdate - 1867216) - 0.25)/36524.25
    sdate <- ifelse(sdate >= 2299161, trunc(sdate + 1 + temp - 
        trunc(0.25 * temp)), sdate)
    jb <- sdate + 1524
    jc <- trunc(6680 + ((jb - 2439870) - 122.1)/365.25)
    jd <- trunc(365.25 * jc)
    je <- trunc((jb - jd)/30.6001)
    day <- (jb - jd) - trunc(30.6001 * je)
    month <- as.integer(ifelse(je > 13, je - 13, je - 1))
    year <- as.integer(ifelse(month > 2, jc - 4716, jc - 4715))
    year <- as.integer(ifelse(year <= 0, year - 1, year))
    if (weekday) 
        list(month = month, day = day, year = year, weekday = wday)
    else list(month = month, day = day, year = year)
}

conv_dates <- jul_conv(df1$jul_start_date, weekday = TRUE)
df1$s_month <- factor(conv_dates$month)
df1$s_day <- factor(conv_dates$day)
df1$weekday <- factor(conv_dates$weekday)
head(df1)
plot(df1$s_day)
plot(df1$s_month)
plot(df1$weekday)
```

```{r}
library(rpart)
library(rpart.plot)
tree <- rpart(duration ~ arrests+know_ini+region+coup,  df1, control = rpart.control(minsplit = 1, minbucket = 1, cp = 0.001))
x <- tail(df1)

result <- predict(tree, x)
print(result)
```


```{r}
rpart.plot(tree, box.palette = "white")
```


The decision tree model isn't working as well as I hoped, Let's try a random forest algorithm.

```{r}
library(randomForest)
library(caret)

rf_df <- subset(df1, select = -c(country, date, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(rf_df$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_data <- rf_df[ trainIndex,]
test_data  <- rf_df[-trainIndex,]

rf <- randomForest(duration ~ ., data = train_data, na.action = na.omit)
rf
varImpPlot(rf)
```


Let's try a multinomial logistic regression model for comparison

```{r}
library(nnet)
library(caret)



MLR <- multinom(duration ~ ., train_data, na.action = na.omit)
#summary(MLR)
test_mlr <- predict(MLR, test_data)

confusionMatrix(test_mlr, test_data$duration)
```
```{r}
test_rf <- predict(rf, test_data)
confusionMatrix(test_rf, test_data$duration)
```

Looks like the random forrest model significantly out-performs the multi-nomial logistic regression model. It looks like most of the prediction errors are made in the class 2. The "longer than a week, less than a month" events are the hardest to identify. Thus let's try a binanry classification model to see if there is a notable improvement in accuracy.

```{r}
df_binary <- df1 %>% mutate(duration = case_when(day_span <= 17 ~ "0",
                            day_span > 17 ~ "1"))
df_binary$duration <- factor(df_binary$duration)
head(df_binary, 25)


```
```{r}
rf_df2 <- subset(df_binary, select = -c(country, date, day, month, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(rf_df2$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
binary_train_data <- rf_df2[ trainIndex,]
binary_test_data  <- rf_df2[-trainIndex,]

rf_binary <- randomForest(duration ~ ., data = binary_train_data, na.action = na.omit)
rf_binary
varImpPlot(rf_binary)
```

```{r}
test_rf_binary <- predict(rf_binary, binary_test_data)
confusionMatrix(test_rf_binary, binary_test_data$duration, positive = '1')
```
```{r}
rf_df3 <- subset(df_binary, select = -c(country, date, day, s_day, month, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(rf_df3$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
binary_train_data3 <- rf_df3[ trainIndex,]
binary_test_data3  <- rf_df3[-trainIndex,]

rf_binary3 <- randomForest(duration ~ ., data = binary_train_data3, na.action = na.omit)
rf_binary3
varImpPlot(rf_binary3)

```
```{r}
test_rf_binary3 <- predict(rf_binary3, binary_test_data3)
confusionMatrix(test_rf_binary3, binary_test_data3$duration, positive = '1')
```
Why is the day of the month so predictive?

```{r}
plot(df_binary$duration ~ df_binary$s_day)
```
The first day of the month looks to be extremely predictive. but if we look at how the events are coded, it seems that the most of the events were had to use an estimated start date instead of a precise one. This could play a factor if estimated dates for longer term events were just pegged to the first of a month.
```{r}
#number of observations coded as estimated start date instead of precise start date
sum(is.na(data_raw$jul_psd))
```
Given this line of thinking, there is too much risk of the s_day value over-influencing the model if the information of start dates isn't highly accurate. It may be better to drop the date and month variables and rely on other factors. This may hurt the scores on the evaluations, but the model may perform better in the wild as a result.
```{r}
df_16_7 <- df_binary %>% mutate(day1 = ifelse(s_day == 1, TRUE,FALSE),
                            month1 = ifelse(month == 1, TRUE,FALSE))
head(df_16_7)
```

```{r}
rf_df4 <- subset(df_16_7, select = -c(country, date, day, month,s_day, s_month, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(rf_df4$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
binary_train_data4 <- rf_df4[ trainIndex,]
binary_test_data4  <- rf_df4[-trainIndex,]

rf_binary4 <- randomForest(duration ~ ., data = binary_train_data4, na.action = na.omit)
rf_binary4
varImpPlot(rf_binary4)
```

```{r}
test_rf_binary4 <- predict(rf_binary4, binary_test_data4)
confusionMatrix(test_rf_binary3, binary_test_data3$duration, positive = '1')
```

I'm going to replace the s_day variable with a categorical 'week' variable (week of the month)
```{r}
df_binary <- df_binary %>% mutate(week = case_when(s_day <= 7 ~ "1",
                            day > 7 & day <= 14 ~ "2", 
                           day > 14 & day <= 21 ~ "3",
                           day > 21 & day <= 28 ~ "4",
                           day > 28 ~ "5"))
df_binary$week <- factor(df_binary$week)
head(df_binary)
```

```{r}
rf_df5 <- subset(df_binary, select = -c(country, date, day, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(rf_df5$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
binary_train_data5 <- rf_df5[ trainIndex,]
binary_test_data5  <- rf_df5[-trainIndex,]

rf_binary5 <- randomForest(duration ~ ., data = binary_train_data5, na.action = na.omit)
rf_binary5
varImpPlot(rf_binary5)
```
```{r}
test_rf_binary5 <- predict(rf_binary5, binary_test_data5)
confusionMatrix(test_rf_binary5, binary_test_data5$duration, positive = '1')
```

That looks like a pretty decent model. Lets compare with a logistic regression once more

```{r}
logit1 <- glm(duration ~ ., family = 'binomial', data = binary_train_data5)
summary(logit1)

```

```{r}
test_logit1 <- predict(logit1, binary_test_data5)
predicted.classes <- ifelse(test_logit1 > 0.5, 1, 0)
confusionMatrix(factor(predicted.classes), binary_test_data5$duration, positive = '1')
```

```{r}
rf_t10_df <- subset(df_binary, select = c(month, week, loc_type, region, weapon, n_killed_a, know_ini, ev_type, sc_animosity, anti_gov_sentmnts, duration))

trainIndex <- createDataPartition(rf_t10_df$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
binary_train_t10 <- rf_t10_df[ trainIndex,]
binary_test_t10  <- rf_t10_df[-trainIndex,]

rf_t10 <- randomForest(duration ~ ., data = binary_train_t10, na.action = na.omit)
rf_t10
varImpPlot(rf_t10)
```
```{r}
test_rf_t10 <- predict(rf_t10, binary_test_t10)
confusionMatrix(test_rf_t10, binary_test_t10$duration, positive = '1')
```

This is a much more simple model that has similar perfomance to the one with all the variables. 


```{r}
day16 <- filter(df_binary, day == 16)
day16
```



```{r}
asia <- filter(df_binary, region == '2') %>% subset(select = -c(country, date, day, day_span, jul_start_date, jul_end_date, e_length))

trainIndex <- createDataPartition(asia$duration, p = .8, 
                                  list = FALSE, 
                                  times = 1)
asia_train <- asia[ trainIndex,]
asia_test  <- asia[-trainIndex,]

rf_asia <- randomForest(duration ~ ., data = asia_train, na.action = na.omit)
rf_asia
varImpPlot(rf_asia)

```

```{r}
test_asia <- predict(rf_asia, asia_test)
confusionMatrix(test_asia, asia_test$duration, positive = '1')
```


```{r}
df716 <- df_binary %>% filter(day == 16, month == '7')

```

```{r}
library(ggplot2)
plot(df1$s_month, main = "Events by Month", xlab = "Month", ylab = "Frequency")
plot(df1$s_day, main = "Events by Start Day", xlab = "Day", ylab = "Frequency")
plot(df716$region, main = "7/16 Events, by Region", xaxt = "n")
xtick = c("SS Africa", "Asia", "Europe", "LatAm&Car", "Canada", "Oceania", "N Africa", "MidEast")
#axis(side=1, at=seq(0.5, 10, 1.25), labels = FALSE)
text(x=seq(0.75, 10, 1.25),  par("usr")[3], 
     labels = xtick, srt = 60, pos = 2.5, xpd = TRUE)

```

```{r}
x <- df_binary %>% filter(duration == '1')
plot(duration ~ loc_type, df2)
```












